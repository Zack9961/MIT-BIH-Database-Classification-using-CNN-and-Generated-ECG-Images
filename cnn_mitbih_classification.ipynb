{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2643111c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a05e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function.\n",
    "def train(epoch, model, loader, criterion, optimizer, device='cpu'):\n",
    "    l = 0\n",
    "    for data in tqdm(loader, desc=f'Epoch {epoch+1:03d}'):\n",
    "        x = data[0].to(device)\n",
    "        y = data[1].squeeze().to(device)\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        l += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    return l\n",
    "\n",
    "# Test function.\n",
    "def test(model, loader, criterion, device='cpu'):\n",
    "    l = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            x = data[0].to(device)\n",
    "            y = data[1].squeeze().to(device)\n",
    "            out = model(x)\n",
    "            l += criterion(out, y)\n",
    "            _, pred = torch.max(out.data, 1)\n",
    "            total += y.size(0)\n",
    "            correct += (pred == y).sum().item()\n",
    "            y_true += y.tolist()\n",
    "            y_pred += pred.tolist()\n",
    "    return l, correct / total, y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88f4fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImmaginiDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # Carica le immagini e le etichette\n",
    "        for file in os.listdir(root_dir):\n",
    "            if file.endswith(\".jpg\") or file.endswith(\".png\"):\n",
    "                img_path = os.path.join(root_dir, file)\n",
    "                label = int(file.split(\"_\")[0])  # supponendo che le etichette siano nel nome file\n",
    "                self.images.append(img_path)\n",
    "                self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(img_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Impostazioni\n",
    "root_dir = \"path/to/your/images\"\n",
    "train_dir = os.path.join(root_dir, \"train\")\n",
    "test_dir = os.path.join(root_dir, \"test\")\n",
    "\n",
    "# Transformation per il training\n",
    "train_transformations = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Adatta le immagini alla dimensione richiesta\n",
    "    transforms.RandomCrop(224, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Transformation per il test\n",
    "test_transformations = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Creazione dei dataset\n",
    "train_dataset = ImmaginiDataset(train_dir, transform=train_transformations)\n",
    "test_dataset = ImmaginiDataset(test_dir, transform=test_transformations)\n",
    "\n",
    "# Creazione dei dataloader\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89f1f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training transformations.\n",
    "train_transformations = transforms.Compose([\n",
    "    transforms.RandomCrop(224, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Datasets.\n",
    "train_dataset = DermaMNIST(split='train',\n",
    "                           transform=train_transformations,\n",
    "                           download=True,\n",
    "                           size=224)\n",
    "test_dataset = DermaMNIST(split='test',\n",
    "                          transform=transforms.ToTensor(),\n",
    "                          download=True,\n",
    "                          size=224)\n",
    "\n",
    "# Loaders.\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=64,\n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=64,\n",
    "                                          shuffle=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
